{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor flow development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for binary classification\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "TITANIC_TRAIN = \"/data/train.csv\"\n",
    "\n",
    "names = [\"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "data = pd.read_csv(TITANIC_TRAIN, names=names, skiprows=1)\n",
    "\n",
    "# Train and test input data\n",
    "data = data.drop([\"Name\",\"PassengerId\",\"Cabin\",\"Ticket\"], axis=1)\n",
    "data['Sex'] = pd.factorize(data.Sex)[0]\n",
    "data['Embarked'] = pd.factorize(data.Embarked)[0]\n",
    "\n",
    "# We have NaN values in Age. We substitute them by the average\n",
    "data[\"Age\"] = data.Age.fillna(data.Age.mean())\n",
    "\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex       Age  SibSp     Parch      Fare  Embarked\n",
      "0       1.0  0.0  0.271174  0.125  0.000000  0.014151  0.333333\n",
      "1       0.0  1.0  0.472229  0.125  0.000000  0.139136  0.666667\n",
      "2       1.0  1.0  0.321438  0.000  0.000000  0.015469  0.333333\n",
      "3       0.0  1.0  0.434531  0.125  0.000000  0.103644  0.333333\n",
      "4       1.0  0.0  0.434531  0.000  0.000000  0.015713  0.333333\n",
      "..      ...  ...       ...    ...       ...       ...       ...\n",
      "886     0.5  0.0  0.334004  0.000  0.000000  0.025374  0.333333\n",
      "887     0.0  1.0  0.233476  0.000  0.000000  0.058556  0.333333\n",
      "888     1.0  1.0  0.367921  0.125  0.333333  0.045771  0.333333\n",
      "889     0.0  0.0  0.321438  0.000  0.000000  0.058556  0.666667\n",
      "890     1.0  0.0  0.396833  0.000  0.000000  0.015127  1.000000\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Configure the Adam optimization\n",
    "Adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64, verbose=0, validation_split=0.33)\n",
    "\n",
    "# We defenitely have a problem of variance or overfitting. We should regularize.\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Cross Entropy')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# Next steps\n",
    "# 1. Regularization\n",
    "# 2. Add Cabin, Ticket or even Name attributes to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
