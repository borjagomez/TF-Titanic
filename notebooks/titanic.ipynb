{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tensor flow development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for binary classification\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(a, b):\n",
    "    if (len(a) > 0):\n",
    "        a = a[0]\n",
    "    else:\n",
    "        a = 0\n",
    "\n",
    "    if (len(b) > 0):\n",
    "        b = b[0]\n",
    "    else:\n",
    "        b = 0\n",
    "\n",
    "    return a + b\n",
    "\n",
    "def prepare_data(data, names, isTraining = True):\n",
    "    # We have NaN values\n",
    "    data[\"Age\"] = data.Age.fillna(data.Age.mean())\n",
    "    data[\"Cabin\"] = data.Cabin.fillna(\"\")\n",
    "\n",
    "    # Let's calculate number of tickets\n",
    "    data[\"numberCabins\"] = [len(re.findall(\"[A-Z]\", i)) for i in data[\"Cabin\"]]\n",
    "    data[\"classTicket\"] = [re.findall(\"[A-Z]\", i) for i in data[\"Cabin\"]]\n",
    "    classTickets = []\n",
    "    for item in data[\"classTicket\"]:\n",
    "        if len(item) > 0:\n",
    "            classTickets.append(item[0])\n",
    "        else:\n",
    "            classTickets.append(\"\")\n",
    "\n",
    "    data[\"classTicket\"] = classTickets\n",
    "\n",
    "    # Train and test input data\n",
    "    data['Sex'] = pd.factorize(data.Sex)[0]\n",
    "    data['Embarked'] = pd.factorize(data.Embarked)[0]\n",
    "    data['classTicket'] = pd.factorize(data.classTicket)[0]\n",
    "\n",
    "    # define the document\n",
    "    listNames = []\n",
    "    for item in data[\"Name\"]:\n",
    "        listNames.extend(item.split(\" \"))\n",
    "    \n",
    "    separator = \" \"\n",
    "    listNames = separator.join(listNames)\n",
    "    listNames = text_to_word_sequence(listNames)\n",
    "    \n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(listNames)\n",
    "    \n",
    "    names = []\n",
    "    for name in data[\"Name\"]:\n",
    "        number = sum(t.texts_to_sequences(name), [])\n",
    "        names.append(len(number))\n",
    "            \n",
    "    #data[\"Name\"] = names\n",
    "    \n",
    "\n",
    "    if (isTraining):\n",
    "        X = data.drop([\"PassengerId\", \"Ticket\", \"Survived\", \"Cabin\", \"Name\"], axis=1)\n",
    "        y = data[\"Survived\"]\n",
    "    else:\n",
    "        X = data.drop([\"PassengerId\", \"Ticket\",\"Cabin\", \"Name\"], axis=1)        \n",
    "        y = []\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)   \n",
    "    \n",
    "    return [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "TITANIC_TRAIN = \"/data/train.csv\"\n",
    "TITANIC_TEST = \"/data/test.csv\"\n",
    "\n",
    "names = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "data = pd.read_csv(TITANIC_TRAIN)\n",
    "test = pd.read_csv(TITANIC_TEST)\n",
    "\n",
    "X = pd.get_dummies(data[names])\n",
    "X_test = pd.get_dummies(test[names])\n",
    "\n",
    "y = data['Survived']\n",
    "\n",
    "#[X, y] = prepare_data(data, names)\n",
    "#[X_test, _] = prepare_data(test, names_training, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  SibSp  Parch  Sex_female  Sex_male\n",
      "0         3      1      0           0         1\n",
      "1         1      1      0           1         0\n",
      "2         3      0      0           1         0\n",
      "3         1      1      0           1         0\n",
      "4         3      0      0           0         1\n",
      "..      ...    ...    ...         ...       ...\n",
      "886       2      0      0           0         1\n",
      "887       1      0      0           1         0\n",
      "888       3      1      2           1         0\n",
      "889       1      0      0           0         1\n",
      "890       3      0      0           0         1\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "     Pclass  SibSp  Parch  Sex_female  Sex_male\n",
      "0         3      0      0           0         1\n",
      "1         3      1      0           1         0\n",
      "2         2      0      0           0         1\n",
      "3         3      0      0           0         1\n",
      "4         3      1      1           1         0\n",
      "..      ...    ...    ...         ...       ...\n",
      "413       3      0      0           0         1\n",
      "414       1      0      0           1         0\n",
      "415       3      0      0           0         1\n",
      "416       3      0      0           0         1\n",
      "417       3      1      1           0         1\n",
      "\n",
      "[418 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(prediction)\n",
    "\n",
    "# Next steps\n",
    "# 1. Regularization\n",
    "# 2. Add Cabin, Ticket or even Name attributes to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test)\n",
    "y_test[y_test > 0.5] = int(1)\n",
    "y_test[y_test <= 0.5] = int(0)\n",
    "y_test[np.isnan(y_test)] = int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-07077cfd736b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     result.append({\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     })\n\u001b[1;32m      8\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "result = []\n",
    "for yvalue in y_test:\n",
    "    result.append({\n",
    "        \"PassengerId\": test[\"PassengerId\"][idx], \n",
    "        \"Survived\": int(yvalue[0])\n",
    "    })\n",
    "    idx = idx + 1\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv('/data/prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
